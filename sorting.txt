1. Bubble Sort
    Time Complexity:
    Best: O(n)
    Average: O(n²)
    Worst: O(n²)
    Space Complexity: O(1)
    Stable: ✅ Yes
    In-place: ✅ Yes

    Implementation

    def bubble_sort(arr):
        n = len(arr)
        for i in range(n):
            swapped = False
            for j in range(n - i - 1):
                if arr[j] > arr[j + 1]:
                    arr[j], arr[j + 1] = arr[j + 1], arr[j]
                    swapped = True
            if not swapped:
                break  # Optimization: Stop if already sorted
        return arr

    arr = [64, 34, 25, 12, 22, 11, 90]
    print(bubble_sort(arr))

2. Selection Sort
    Time Complexity:
    Best: O(n²)
    Average: O(n²)
    Worst: O(n²)
    Space Complexity: O(1)
    Stable: ❌ No
    In-place: ✅ Yes
    Implementation

    def selection_sort(arr):
        n = len(arr)
        for i in range(n):
            min_idx = i
            for j in range(i + 1, n):
                if arr[j] < arr[min_idx]:
                    min_idx = j
            arr[i], arr[min_idx] = arr[min_idx], arr[i]
        return arr

    arr = [64, 25, 12, 22, 11]
    print(selection_sort(arr))

3. Insertion Sort
    Time Complexity:
    Best: O(n)
    Average: O(n²)
    Worst: O(n²)
    Space Complexity: O(1)
    Stable: ✅ Yes
    In-place: ✅ Yes
    Implementation

    def insertion_sort(arr):
        for i in range(1, len(arr)):
            key = arr[i]
            j = i - 1
            while j >= 0 and arr[j] > key:
                arr[j + 1] = arr[j]
                j -= 1
            arr[j + 1] = key
        return arr

    arr = [12, 11, 13, 5, 6]
    print(insertion_sort(arr))

4. Merge Sort
    Time Complexity:
    Best: O(n log n)
    Average: O(n log n)
    Worst: O(n log n)
    Space Complexity: O(n)
    Stable: ✅ Yes
    In-place: ❌ No
    Implementation

    def merge_sort(arr):
        if len(arr) > 1:
            mid = len(arr) // 2
            left_half = arr[:mid]
            right_half = arr[mid:]

            merge_sort(left_half)
            merge_sort(right_half)

            i = j = k = 0

            while i < len(left_half) and j < len(right_half):
                if left_half[i] < right_half[j]:
                    arr[k] = left_half[i]
                    i += 1
                else:
                    arr[k] = right_half[j]
                    j += 1
                k += 1

            while i < len(left_half):
                arr[k] = left_half[i]
                i += 1
                k += 1

            while j < len(right_half):
                arr[k] = right_half[j]
                j += 1
                k += 1

        return arr

    arr = [38, 27, 43, 3, 9, 82, 10]
    print(merge_sort(arr))

5. Quick Sort
    Time Complexity:
    Best: O(n log n)
    Average: O(n log n)
    Worst: O(n²) (when the pivot is poorly chosen)
    Space Complexity: O(log n) (due to recursion)
    Stable: ❌ No
    In-place: ✅ Yes
    Implementation

    def quick_sort(arr):
        if len(arr) <= 1:
            return arr
        pivot = arr[len(arr) // 2]
        left = [x for x in arr if x < pivot]
        middle = [x for x in arr if x == pivot]
        right = [x for x in arr if x > pivot]
        return quick_sort(left) + middle + quick_sort(right)

    arr = [10, 7, 8, 9, 1, 5]
    print(quick_sort(arr))

6. Heap Sort
    Time Complexity:
    Best: O(n log n)
    Average: O(n log n)
    Worst: O(n log n)
    Space Complexity: O(1)
    Stable: ❌ No
    In-place: ✅ Yes
    Implementation

    import heapq

    def heap_sort(arr):
        heapq.heapify(arr)
        return [heapq.heappop(arr) for _ in range(len(arr))]

    arr = [12, 11, 13, 5, 6, 7]
    print(heap_sort(arr))

7. Counting Sort (for small range of numbers)
    Time Complexity:
    Best: O(n + k)
    Average: O(n + k)
    Worst: O(n + k)
    Space Complexity: O(k)
    Stable: ✅ Yes
    In-place: ❌ No
    Implementation

    def counting_sort(arr):
        max_val = max(arr)
        count = [0] * (max_val + 1)
        
        for num in arr:
            count[num] += 1

        sorted_arr = []
        for i, freq in enumerate(count):
            sorted_arr.extend([i] * freq)

        return sorted_arr

    arr = [4, 2, 2, 8, 3, 3, 1]
    print(counting_sort(arr))

8. Radix Sort (for integers only)
    Time Complexity:
    Best: O(nk)
    Average: O(nk)
    Worst: O(nk)
    Space Complexity: O(n + k)
    Stable: ✅ Yes
    In-place: ❌ No
    Implementation

    def counting_sort_for_radix(arr, exp):
        n = len(arr)
        output = [0] * n
        count = [0] * 10

        for num in arr:
            index = (num // exp) % 10
            count[index] += 1

        for i in range(1, 10):
            count[i] += count[i - 1]

        for i in range(n - 1, -1, -1):
            index = (arr[i] // exp) % 10
            output[count[index] - 1] = arr[i]
            count[index] -= 1

        for i in range(n):
            arr[i] = output[i]

    def radix_sort(arr):
        max_val = max(arr)
        exp = 1
        while max_val // exp > 0:
            counting_sort_for_radix(arr, exp)
            exp *= 10

    arr = [170, 45, 75, 90, 802, 24, 2, 66]
    radix_sort(arr)
    print(arr)


Best for General Use (Balanced Time & Space Complexity)
➡ Merge Sort vs Quick Sort vs Heap Sort

Merge Sort: ✅ O(n log n) time, ❌ O(n) space (not in-place)
Quick Sort: ✅ O(n log n) time (average), ✅ O(log n) space (in-place)
Heap Sort: ✅ O(n log n) time, ✅ O(1) space, but ❌ not stable
🔹 Winner: Quick Sort (for in-place sorting, when optimized with good pivot selection like median-of-three or random pivot selection).
🔹 Winner: Merge Sort (if stability is needed and extra space is not an issue).
